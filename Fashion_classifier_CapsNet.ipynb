{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of digit_recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdXqQcX2tgqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpwVbp5eAVdZ",
        "colab_type": "code",
        "outputId": "b112abc4-801d-4088-8921-ffe871f9812c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Connecting to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZYv237gAV2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specifying the location of the dataset and extracting it using pandas read_csv functionality\n",
        "train_dataset = pd.read_csv(\"gdrive/My Drive/dataset/fashion_mnist_train.csv\")\n",
        "test_dataset = pd.read_csv(\"gdrive/My Drive/dataset/fashion_mnist_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92XTfB74AV6h",
        "colab_type": "code",
        "outputId": "3b49a2d8-0cad-4fc2-d9fb-e15e9c0f925b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f\"Train dataset dimensions : {train_dataset.shape}\")\n",
        "print(f\"Test dataset dimensions : {test_dataset.shape}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset dimensions : (60000, 785)\n",
            "Test dataset dimensions : (10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8DJIy9jC-qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping the label column from test and train datasets and forming x_train and x_test respectively\n",
        "# Putting the labels into a separate y_train and y_test dataframe.\n",
        "x_train = train_dataset.drop(columns=[\"label\"])\n",
        "y_train = train_dataset[\"label\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBx8L1Ju2e1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = test_dataset.drop(columns=[\"label\"])\n",
        "y_test = test_dataset[\"label\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nje8DfyFC-tb",
        "colab_type": "code",
        "outputId": "d459e20b-6512-4ed5-bfea-b7b0dfb1cbdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Normalizing the train dataset by setting the value of pixel colors in the range 0 to 1\n",
        "x_train = x_train.to_numpy()/255.0\n",
        "print(f\"Train dataset dimensions : {x_train.shape}\")\n",
        "\n",
        "x_test = x_test.to_numpy()/255.0\n",
        "print(f\"Test dataset dimensions : {x_test.shape}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset dimensions : (60000, 784)\n",
            "Test dataset dimensions : (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPnuLgFEDIXO",
        "colab_type": "code",
        "outputId": "ccde4623-1f29-4ff5-a5e5-adb253a49af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Converting labels pandas dataframe to numpy arrays\n",
        "y_train = y_train.to_numpy()\n",
        "print(f\"Train dataset labels dimensions : {y_train.shape}\")\n",
        "\n",
        "y_test = y_test.to_numpy()\n",
        "print(f\"Test dataset labels dimensions : {y_test.shape}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset labels dimensions : (60000,)\n",
            "Test dataset labels dimensions : (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WSba8pMDJi1",
        "colab_type": "code",
        "outputId": "dbf59c05-c38b-4656-e1ec-235c14d5c2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Reshaping the test and train data to a 4D matrix : [instances, 28, 28, 1] \n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1)).astype('float32')\n",
        "\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1)).astype('float32')\n",
        "\n",
        "# one hot encoded test and train labels:\n",
        "y_train = tf.keras.utils.to_categorical(y_train.astype('float32'))\n",
        "\n",
        "y_test = tf.keras.utils.to_categorical(y_test.astype('float32'))\n",
        "\n",
        "print(f\"Train dataset dimensions : {x_train.shape}\")\n",
        "print(f\"Train dataset labels dimensions : {y_train.shape}\")\n",
        "print(f\"Test dataset dimensions : {x_test.shape}\")\n",
        "print(f\"Test dataset labels dimensions : {y_test.shape}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset dimensions : (60000, 28, 28, 1)\n",
            "Train dataset labels dimensions : (60000, 10)\n",
            "Test dataset dimensions : (10000, 28, 28, 1)\n",
            "Test dataset labels dimensions : (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxEk3tdDuAFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Length(tf.keras.layers.Layer):\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.keras.backend.sqrt(tf.keras.backend.sum(tf.keras.backend.square(inputs), -1))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWj3FzlrtyBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mask(tf.keras.layers.Layer):\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        \n",
        "        if type(inputs) is list:  # true label is provided with shape = [batch_size, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of vectors of capsules\n",
        "            x = inputs\n",
        "            # Enlarge the range of values in x to make max(new_x)=1 and others < 0\n",
        "            x = (x - tf.keras.backend.max(x, 1, True)) / tf.keras.backend.epsilon() + 1\n",
        "            mask = tf.keras.backend.clip(x, 0, 1)  # the max value in x clipped to 1 and other to 0\n",
        "\n",
        "        # masked inputs, shape = [batch_size, dim_vector]\n",
        "        inputs_masked = tf.keras.backend.batch_dot(inputs, mask, [1, 1])\n",
        "        return inputs_masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][-1]])\n",
        "        else:\n",
        "            return tuple([None, input_shape[-1]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efdcX9x3tz14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squash_function(x, axis=-1):\n",
        "    s_squared_norm = tf.keras.backend.sum(tf.keras.backend.square(x), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / tf.keras.backend.sqrt(s_squared_norm)\n",
        "    return scale * x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT_dW8AXt0eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Capsule(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_capsule, dimension_vector, num_routing=3, kernel_initializer='glorot_uniform',\n",
        "                bias_initializer='zeros', **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule \n",
        "        self.dimension_vector = dimension_vector\n",
        "        self.num_routing = num_routing\n",
        "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3\n",
        "        self.input_num_capsule = int(input_shape[1])\n",
        "        self.input_dim_vector = int(input_shape[2])\n",
        "        self.W = self.add_weight(shape=[self.input_num_capsule, self.num_capsule, self.input_dim_vector, self.dimension_vector], \n",
        "                                initializer=self.kernel_initializer, name='W')\n",
        "        \n",
        "        self.bias = self.add_weight(shape=[1, self.input_num_capsule, self.num_capsule, 1, 1], \n",
        "                                   initializer=self.bias_initializer, name='bias', trainable=False)\n",
        "        \n",
        "        self.built = True\n",
        "        \n",
        "    def call(self, inputs, training=None):\n",
        "        inputs_expand = tf.keras.backend.expand_dims(tf.keras.backend.expand_dims(inputs, 2), 2)\n",
        "        \n",
        "        inputs_tiled = tf.keras.backend.tile(inputs_expand, [1, 1, self.num_capsule, 1 , 1])\n",
        "        \n",
        "        inputs_hat = tf.scan(lambda ac, x:tf.keras.backend.batch_dot(x, self.W, [3, 2]), \n",
        "                            elems=inputs_tiled, initializer=tf.keras.backend.zeros([self.input_num_capsule, self.num_capsule, 1, self.dimension_vector]))\n",
        "        \n",
        "        assert self.num_routing > 0, 'the num_routing should be > 0.'\n",
        "        \n",
        "        for i in range(self.num_routing):\n",
        "            c = tf.nn.softmax(self.bias, dim=2)\n",
        "            \n",
        "            outputs = squash_function(tf.keras.backend.sum(c * inputs_hat, 1, keepdims=True))\n",
        "            \n",
        "            if i != self.num_routing - 1:\n",
        "                self.bias = self.bias + tf.keras.backend.sum(inputs_hat * outputs, -1, keepdims=True)\n",
        "        \n",
        "        return tf.keras.backend.reshape(outputs, [-1, self.num_capsule, self.dimension_vector])\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dimension_vector]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EL8vevWt2I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PrimaryCap(inputs, dimension_vector, num_channels, kernel_size, strides, padding):\n",
        "    output = tf.keras.layers.Conv2D(filters=dimension_vector*num_channels, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
        "    outputs = tf.keras.layers.Reshape(target_shape=[1152, dimension_vector])(output)\n",
        "    return tf.keras.layers.Lambda(squash_function)(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ5kEER-t5Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CapsNet(input_shape, n_class, num_routing):\n",
        "    \n",
        "    x = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    # Convolutional layer 1:\n",
        "    conv1 = tf.keras.layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "    # Convolutional layer with squash activation function which is later on reshape to [None, num_capsule, dimension_vector]\n",
        "    primarycaps = PrimaryCap(conv1, dimension_vector=8, num_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "    # Capsule layer: Contains the routing algorithm (routing by agreement).\n",
        "    digitcaps = Capsule(num_capsule=n_class, dimension_vector=16, num_routing=num_routing, name='digitcaps')(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='out_caps')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = tf.keras.layers.Input(shape=(n_class,))\n",
        "    masked = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer.\n",
        "    x_recon = tf.keras.layers.Dense(512, activation='relu')(masked)\n",
        "    x_recon = tf.keras.layers.Dense(1024, activation='relu')(x_recon)\n",
        "    x_recon = tf.keras.layers.Dense(784, activation='sigmoid')(x_recon)\n",
        "    x_recon = tf.keras.layers.Reshape(target_shape=[28, 28, 1], name='out_recon')(x_recon)\n",
        "\n",
        "    # two-input-two-output keras Model\n",
        "    return tf.keras.models.Model([x, y], [out_caps, x_recon])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Xz1vjMt5zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def margin_loss(y_true, y_pred):\n",
        "    L = y_true * tf.keras.backend.square(tf.keras.backend.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * tf.keras.backend.square(tf.keras.backend.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return tf.keras.backend.mean(tf.keras.backend.sum(L, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ye48yVlt7sj",
        "colab_type": "code",
        "outputId": "490c0d24-ffe1-4b1f-80df-4cc2aeee7163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "model = CapsNet(input_shape=[28, 28, 1],\n",
        "                n_class=10,\n",
        "                num_routing=3)\n",
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 20, 20, 256)  20992       input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 6, 6, 256)    5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 1152, 8)      0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 1152, 8)      0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (Capsule)             (None, 10, 16)       1474560     lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_2 (Mask)                   (None, 16)           0           digitcaps[0][0]                  \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 512)          8704        mask_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1024)         525312      dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 784)          803600      dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "out_caps (Length)               (None, 10)           0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "out_recon (Reshape)             (None, 28, 28, 1)    0           dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,141,840\n",
            "Trainable params: 8,141,840\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crFNNZs4DU0b",
        "colab_type": "code",
        "outputId": "a4fe4c0c-fd1e-4d8e-f4c6-61dd5f2dd1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=[margin_loss, 'mse'],\n",
        "              loss_weights=[1., 0.0005],\n",
        "              metrics={'out_caps': 'accuracy'})\n",
        "\n",
        "model.fit(x=[x_train, y_train], y=[y_train, x_train], validation_data=[[x_test, y_test], [y_test, x_test]], epochs=1)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "60000/60000 [==============================] - 300s 5ms/sample - loss: 0.1359 - out_caps_loss: 0.1358 - out_recon_loss: 0.0843 - out_caps_acc: 0.8193 - val_loss: 0.0962 - val_out_caps_loss: 0.0961 - val_out_recon_loss: 0.0556 - val_out_caps_acc: 0.8718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f087b1c5f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}